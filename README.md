# ğŸš€ Cascading Free AI API Flow

A robust Python system that automatically switches between multiple free AI API providers for reliable chat completions and text generation. Never worry about rate limits or downtime again!

## âœ¨ Features

- **ğŸ”„ Automatic Fallback**: Seamlessly switches providers when one fails or hits limits
- **ğŸ“Š Usage Tracking**: Monitors daily usage across all providers  
- **âš¡ Exponential Backoff**: Smart retry logic to handle temporary failures
- **ğŸ”§ Modular Design**: Clean, maintainable code split across multiple files
- **ğŸ“ˆ Real-time Stats**: Monitor API consumption and performance
- **ğŸ›¡ï¸ Robust Error Handling**: Comprehensive logging and graceful failures

## ğŸ¯ Supported Free Providers (2025)

| Provider | Daily Limit | Speed | Models |
|----------|-------------|-------|--------|
| **Groq** | 1,000 requests | âš¡ Fastest | Llama 3.3 70B |
| **Cerebras** | 1M tokens | ğŸš€ High throughput | Llama 3.3 70B |
| **OpenRouter** | 200 requests | ğŸ”€ Multi-model | Various free |
| **Together AI** | 500 requests | ğŸ¤ Open source | Llama variants |
| **Mistral** | 200 requests | ğŸ‡«ğŸ‡· European | Mistral 7B |
| **HuggingFace** | 1,000 requests | ğŸ¤— Community | Llama 3.3 70B |
| **Fireworks** | 500 requests | ğŸ† Fast inference | Llama variants |

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Set Up API Keys
```bash
cp .env.example .env
# Edit .env and add your API keys
```

### 3. Test Your Setup
```bash
python test_providers.py
```

### 4. Run Examples
```bash
python example.py
```

## ğŸ“ Project Structure

```
cascading-ai-flow/
â”œâ”€â”€ cascade.py          # Main cascading API client
â”œâ”€â”€ providers.py        # Provider configurations
â”œâ”€â”€ usage_tracker.py    # Usage tracking functionality
â”œâ”€â”€ utils.py           # Utility functions
â”œâ”€â”€ config.py          # Settings and configuration
â”œâ”€â”€ example.py         # Usage examples
â”œâ”€â”€ test_providers.py  # Provider testing script
â”œâ”€â”€ requirements.txt   # Dependencies
â”œâ”€â”€ .env.example      # Environment variables template
â””â”€â”€ README.md         # This file
```

## ğŸ”§ Basic Usage

```python
from cascade import CascadingAPIClient

# Initialize client (uses all available providers)
client = CascadingAPIClient()

# Send a message
messages = [
    {"role": "user", "content": "What is machine learning?"}
]

response = client.chat_completion(messages)
print(response)
```

## ğŸ”‘ API Keys Setup

Get free API keys from these providers:

| Provider | Signup Link | Notes |
|----------|-------------|-------|
| **Groq** | [console.groq.com](https://console.groq.com) | Fastest inference |
| **Cerebras** | [inference.cerebras.ai](https://inference.cerebras.ai) | High throughput |
| **OpenRouter** | [openrouter.ai](https://openrouter.ai) | Multiple models |
| **Together AI** | [api.together.ai](https://api.together.ai) | Open source focus |
| **Mistral** | [console.mistral.ai](https://console.mistral.ai) | European provider |
| **HuggingFace** | [huggingface.co](https://huggingface.co) | Community models |
| **Fireworks** | [fireworks.ai](https://fireworks.ai) | Fast inference |

> ğŸ’¡ **Tip**: You don't need all keys! Start with 2-3 providers and add more later.

## ğŸ§ª Testing

```bash
# Test all providers
python test_providers.py

# Quick test (individual providers only)
python test_providers.py --quick
```

## ğŸ“Š Advanced Usage

```python
from cascade import CascadingAPIClient

client = CascadingAPIClient()

# Custom parameters
response = client.chat_completion(
    messages=messages,
    max_tokens=500,
    temperature=0.8,
    max_retries=3
)

# Get usage statistics
stats = client.get_usage_stats()
print(stats)
```

## ğŸ”§ Configuration

Edit `config.py` to customize:
- Logging levels and file locations
- Default API parameters
- Retry and backoff settings
- Usage tracking options

## ğŸ“ˆ Monitoring

The system automatically:
- Tracks daily usage in `usage_tracking.json`
- Logs all activity to `cascade_api.log`
- Resets usage counters daily
- Provides real-time statistics

## ğŸ› Troubleshooting

**No providers available**
- Check API keys in `.env` file
- Run `python test_providers.py` to verify setup

**Rate limit errors**
- System handles automatically with backoff
- Check usage with `client.get_usage_stats()`

**API errors**
- Check `cascade_api.log` for detailed errors
- Verify model names are correct

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

MIT License - use freely in your projects!

## ğŸ™ Acknowledgments

Thanks to all AI providers offering free tiers and the developer community for inspiration.

---

â­ **Star this repo if it helps you!** â­
